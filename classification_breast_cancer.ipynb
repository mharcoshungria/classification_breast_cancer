{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification_breast_cancer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Projeto I - Aplicação de Métodos de Aprendizagem de Máquina.**"
      ],
      "metadata": {
        "id": "HWponGHI3a1F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMWaKlNfHoLk"
      },
      "source": [
        "##Detecção de tipos de tumor de mama: Benignos e Malignos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDHHzR1vHoHi"
      },
      "source": [
        "# **Etapa 01:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIMUXVpvH2-5"
      },
      "source": [
        "> **Problemática**\n",
        "\n",
        "Os tumores benignos crescem devagar e de forma limitada; já os tumores malignos, em geral, crescem rápido e tendem a ser invasivos. \n",
        "\n",
        "Segundo o Instituto Nacional de Câncer - INCA, há vários tipos de câncer de mama. Por isso, a doença pode evoluir de diferentes formas. Alguns tipos têm desenvolvimento rápido, enquanto outros crescem mais lentamente. \n",
        "\n",
        "Esses comportamentos distintos se devem a característica próprias de cada tumor.\n",
        "\n",
        "E a incidência estimada de câncer de mama nas mulheres corresponde a 29,7%. Para fins de comparação, nenhum outro tipo de câncer, neste levantamento, ultrapassou a margem de 10%.\n",
        "\n",
        "\n",
        "Fonte: < https://www.inca.gov.br/controle-do-cancer-de-mama/conceito-e-magnitude >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCVF6RT9Jwm3"
      },
      "source": [
        "> **Objetivo**\n",
        "\n",
        "Utilizaremos uma base de dados com dois tipos de tumores, são eles: Benignos e Malignos. De acordo com determinadas características (Features), vamos prever nossas respostas (Targets). \n",
        "\n",
        "Em resumo, vamos ensinar máquinas a realizar diagósticos (com a maior taxa de acerto possível), baseados em dados históricos e asssim otimizar o diagnóstico do paciênte para que ele possa iniciar o tratamento o quanto antes.\n",
        "\n",
        "> **Especificação Técnica**\n",
        "\n",
        "**Dataset:** Para desenvolvimento desse projeto, vamos trabalhar com um conjunto de dados do câncer de mama em Wisconsin, um estado dos EUA, disponível em: < https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic) >.\n",
        "\n",
        "**Formato**: A base de dados está em formato .DATA e possui 569 linhas, distribuidas entre 31 colunas.\n",
        "\n",
        "> **Métodos de Pŕe-processamento:** \n",
        "\n",
        "Destaca-se como os pré-processsamento os seguintes passos:\n",
        "\n",
        "* Limpeza da base: Para fins didáticos, estamos trabalhando com uma base de dados já pré-preparada, em resumo, sem campos nulos, ou dados faltantes.\n",
        "* Transformação para DataFrame, pois ao transformar nossa base em dataframe poderemos trabalhar mais poderosamente nossos dados com à ajuda do pacote Pandas.\n",
        "\n",
        "> **Tarefa de Aprendizado**: \n",
        "\n",
        "Será aplicado a tarefa de Classificação \n",
        "\n",
        "> **Algoritmos Avaliados**: \n",
        "\n",
        "Serão avaliados os seguintes algoritmos: Regressão Logística, Máquina de Vetores de Suporte e Floresta Aleatória.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ0jW1-LLGls"
      },
      "source": [
        "## **Etapa 02:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ActYxADwSgm_"
      },
      "source": [
        "**01. Importando as bibliotecas:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81DI3_ued3sp"
      },
      "source": [
        "# Manipulação de dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualização de dados\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning \n",
        "from sklearn import metrics # analisa a acurácia de nossos modelos\n",
        "\n",
        "# Ocultando Warnings indesejados\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAJpkpP1Spf2"
      },
      "source": [
        "**02. Importação do dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUX_LdkleajB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "907ad806-c610-4093-f345-96735167eeb2"
      },
      "source": [
        "# Existem várias bases de dados disponíveis de forma nátiva no pacote Sklearn do Python e vamos usar a load_breast_cancer.\n",
        "# É o mesmo dataset do câncer de mama em Wisconsin.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer #importando a base de dados nativas no sklearn\n",
        "\n",
        "dados=load_breast_cancer() # Carregando base de dados\n",
        "\n",
        "# Agora vamos ver a descrição de nossa base de dados:\n",
        "print(dados.DESCR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry \n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
            "        13 is Radius SE, field 23 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVmqXfAyCT3Q"
      },
      "source": [
        "**Em resuno, vamos encontrar todas essas informações:**\n",
        "\n",
        "* raio (média das distâncias do centro aos pontos no perímetro)\n",
        "* textura (desvio padrão dos valores da escala de cinza)\n",
        "* perímetro\n",
        "* área\n",
        "* suavidade (variação local nos comprimentos dos raios)\n",
        "* compacidade (perímetro ^ 2 / área - 1,0)\n",
        "* concavidade (severidade das porções côncavas do contorno)\n",
        "* pontos côncavos (número de porções côncavas do contorno)\n",
        "* simetria\n",
        "* dimensão fractal (\"aproximação do litoral\" - 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBUgBkROJH_i"
      },
      "source": [
        "cancer=pd.DataFrame(data=dados.data, columns=dados.feature_names) # Convertendo o nosso conjunto de dados para um dataframe com ajuda do Pandas.\n",
        "\n",
        "cancer['Class']=dados.target # Agora estamos adicionando a nossa Target."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZIbR70KS4oo"
      },
      "source": [
        "**03. Tranformando a base de dados em um DataFrame:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyb73VCtJbhP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "11bef2a5-c6a9-498f-ae5b-b502c78d1b68"
      },
      "source": [
        "# Um dataframe Pandas parece muito com uma tabela Excel ou um banco de dados relacional, como o MySQL.\n",
        "\n",
        "cancer.head(10) # Visualizando as 10 primeiras linhas de nosso dataframe."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.03345</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.01137</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.05742</td>\n",
              "      <td>0.4467</td>\n",
              "      <td>0.7732</td>\n",
              "      <td>3.180</td>\n",
              "      <td>53.91</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>0.01382</td>\n",
              "      <td>0.02254</td>\n",
              "      <td>0.01039</td>\n",
              "      <td>0.01369</td>\n",
              "      <td>0.002179</td>\n",
              "      <td>22.88</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.1932</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>0.07451</td>\n",
              "      <td>0.5835</td>\n",
              "      <td>1.3770</td>\n",
              "      <td>3.856</td>\n",
              "      <td>50.96</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.03029</td>\n",
              "      <td>0.02488</td>\n",
              "      <td>0.01448</td>\n",
              "      <td>0.01486</td>\n",
              "      <td>0.005412</td>\n",
              "      <td>17.06</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.1556</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.07389</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>1.0020</td>\n",
              "      <td>2.406</td>\n",
              "      <td>24.32</td>\n",
              "      <td>0.005731</td>\n",
              "      <td>0.03502</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>0.01226</td>\n",
              "      <td>0.02143</td>\n",
              "      <td>0.003749</td>\n",
              "      <td>15.49</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>0.2976</td>\n",
              "      <td>1.5990</td>\n",
              "      <td>2.039</td>\n",
              "      <td>23.94</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.07217</td>\n",
              "      <td>0.07743</td>\n",
              "      <td>0.01432</td>\n",
              "      <td>0.01789</td>\n",
              "      <td>0.010080</td>\n",
              "      <td>15.09</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.2210</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  Class\n",
              "0        17.99         10.38  ...                  0.11890      0\n",
              "1        20.57         17.77  ...                  0.08902      0\n",
              "2        19.69         21.25  ...                  0.08758      0\n",
              "3        11.42         20.38  ...                  0.17300      0\n",
              "4        20.29         14.34  ...                  0.07678      0\n",
              "5        12.45         15.70  ...                  0.12440      0\n",
              "6        18.25         19.98  ...                  0.08368      0\n",
              "7        13.71         20.83  ...                  0.11510      0\n",
              "8        13.00         21.82  ...                  0.10720      0\n",
              "9        12.46         24.04  ...                  0.20750      0\n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2PChRnUS77P"
      },
      "source": [
        "**04. Explorando a nossa base de dados:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfzKnuQDKVC8",
        "outputId": "a6f4552a-cad4-453d-92aa-044c861933bc"
      },
      "source": [
        "# Vamos começar descobrindo as dimensões de nosso dataframe - Linhas X Colunas\n",
        "cancer.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h8Frm5qOnj8"
      },
      "source": [
        "São 30 colunas + a nossa target na última coluna ['Class'].\n",
        "\n",
        "Nosso objetivo será, com base nas 30 colunas (nossas features), prever a classificação entre Maligno=0 e Benigno=1 (nossa target).\n",
        "\n",
        "A target é a nossa variável de resposta, ela contêm dados reais sobre diagnósticos. Como vimos, nossas base de dados tem 569 linhas, ou seja, temos dados sobre 569 diagnósticos diferentes entre tumores benigno e maligno.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buv0-txpOxVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12dc4f04-aa27-4057-8eef-bbe585001de2"
      },
      "source": [
        "# Vamos começar olhando como estão distribuidos estes diagnósticos:\n",
        "\n",
        "# Distribuição de nossas classes\n",
        "cancer['Class'].value_counts() # 1- Benigno 0 = Maligno"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxiQShgKO_B5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "44338dc0-1ab5-45df-8e58-85ff4e53e360"
      },
      "source": [
        "# Obtemos a seguinte informação: 357 casos benignos e 212 casos malignos.\n",
        "\n",
        "# Para termos uma visualização melhor, vamos criar um Gráfico de Pizza - ou no inglês um gráfico de torta (PiePlot):\n",
        "\n",
        "colors=['#008000','#FF0000'] # Aqui apenas escolhemos as cores que serão utilizadas!\n",
        "\n",
        "labels=cancer['Class'].value_counts().index\n",
        "plt.pie(cancer['Class'].value_counts(),autopct='%1.1f%%',colors=colors) # conta as ocorrências de cada classe e exibe a porcentagem\n",
        "plt.legend(labels,bbox_to_anchor=(1.25,1),) # Nossas Legendas\n",
        "plt.title('Porcentagem: Benignos x Malignos')\n",
        "plt.show()\n",
        "\n",
        "# Reforçando que 1- Benigno 0 = Maligno"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49gG8Er_Pc9L"
      },
      "source": [
        "Como podemos ver, há mais casos de benignos do que de malignos. Entretando é importante que tenhamos uma quantidade balanceada de cada tipo para podermos construir nossos modelos.\n",
        "\n",
        "A nossa base de dados não está muito desequilibrada, mesmo assim é importante que a balancearmos para que no futuro nosso modelo não fique bom apenas em prever casos benignos, ou apenas casos malignos, chamamos isso de **Overfitting**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZgN6uMRP6Em"
      },
      "source": [
        "**Overfitting ou Sobreajuste** é um termo usado em estatística para descrever quando um modelo estatístico se ajusta muito bem ao conjunto de dados anteriormente observado, mas se mostra ineficaz para prever novos resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJQfRrAtTBM6"
      },
      "source": [
        "**05. Limpeza dos dados:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBc5n31DQZzr"
      },
      "source": [
        "Partimos da ideia de ter uma base de dados mais \"equilibrada\" e como já sabemos que temos 357 diagnósticos benignos e 212 malignos, logo concluímos que vamos ter de excluir 145 casos benignos.\n",
        "\n",
        "Para isso, vamos usar todos os casos malignos que temos a disposição (212), mais a mesma quantidade de casos benignos e assim totalizando 424 diagnósticos.\n",
        "\n",
        "Dentre os 357 diagnósticos benignos, devemos escolher os melhores para compor a nova base de dados. Ou seja, dentre os 357 casos, vamos selecionar os melhores 212.\n",
        "\n",
        "Existem diversos critérios que poderiamos levar em consideração! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23nCh9i3U2GR"
      },
      "source": [
        "**Por exemplo:**\n",
        "\n",
        "Possívelmente temos em nossa base de dados, registros ou no caso diagnósticos, onde nem todas as variáveis estão preenchidas, enquanto outros possuem todas as informações. \n",
        "\n",
        "Lógicamente deveriamos dar prioridade para os registros completos!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k7DYQhwR8Md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070a603f-d174-4e59-9444-80681176d1f0"
      },
      "source": [
        "# Neste projeto, para fins didáticos, estamos trabalhando com uma base de dados já pré preparada, ou seja, sem campos nulos, ou dados faltantes.\n",
        "\n",
        "# Veja só:\n",
        "\n",
        "# Misssing Values\n",
        "cancer.isnull().sum() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "Class                      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcqWrjOCSPLv"
      },
      "source": [
        "Então como estamos trabalhando com apenas dados completos e igualmente confiáveis, nosso trabalho será apenas o de selecionar de forma aleatória, ou como chamamos, de forma rândomica os registros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrKHUMUwSX5G"
      },
      "source": [
        "**06. Construção dos modelos:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2n0qamrVKkJ"
      },
      "source": [
        "# Vamos usar mais uma vez a biblioteca Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Primeiro, vamos dividir nossa base de dados entre features e target:\n",
        "X= cancer.iloc[:,0:-1]# Selecionando todas as linhas, da primeira coluna até a penúltima coluna.\n",
        "Y=cancer.iloc[:,-1] # Selecionando todas as linhas da última coluna ['Class'].\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.30,random_state=42)\n",
        "# test-size: neste casos vamos dividir nosso dataset em 70% treino e 30% teste\n",
        "# random_state: vamos selecionar de forma aleatória"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eJGEyu8Vbpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d39dc4-d1be-409b-8ff7-2df3856b6e61"
      },
      "source": [
        "# Agora temos nossas bases de dados para treino e testes \n",
        "print('X treino',x_train.shape)\n",
        "print('X test',x_test.shape)\n",
        "print('Y treino',y_train.shape)\n",
        "print('Y test',y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X treino (398, 30)\n",
            "X test (171, 30)\n",
            "Y treino (398,)\n",
            "Y test (171,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG-N-3j7Rd2F"
      },
      "source": [
        "## **Etapa 03:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uT9fH49Vq6h"
      },
      "source": [
        "**07. Modelos de Machine Learning:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CapLrwNWEzt"
      },
      "source": [
        "**I - Regressão Logística:**\n",
        "\n",
        "A regressão logística é uma técnica estatística que tem como objetivo produzir, a partir de um conjunto de observações, um modelo que permita a predição de valores tomados por uma variável categórica, frequentemente binária, a partir de uma série de variáveis explicativas contínuas e/ou binárias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwayCEGEWLWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4ee892-ea2c-4d39-c148-dc96b3672edb"
      },
      "source": [
        "# Vamos importar o nosso modelo:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg=LogisticRegression() # Criando o modelo...\n",
        "logreg.fit(x_train,y_train) # Treinando o modelo...\n",
        "y_pred=logreg.predict(x_test) # Predizendo...\n",
        "acc_logreg=round(metrics.accuracy_score(y_pred,y_test)*100,1) # Nesta etapa, vamos avaliar a acurácia. Ou seja, Previsões x Resultados.\n",
        "print(\"{}% de acurácia\".format(acc_logreg,)) # Exibindo o resultado..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97.1% de acurácia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdYQeZ0JWuMq"
      },
      "source": [
        "**II - Máquina de Vetores de Suporte:**\n",
        "\n",
        "Máquina de vetores de suporte (Support Vector Machines) é um conceito na ciência da computação para um conjunto de métodos de aprendizado supervisionado que analisam os dados e reconhecem padrões, usado para classificação e análise de regressão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkGPXb3nWt2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88eaee0c-2a20-4a4b-e65a-0c4a0007eda8"
      },
      "source": [
        "# Vamos importar o nosso modelo:\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc=SVC() # Criando o modelo...\n",
        "svc.fit(x_train,y_train) # Treinando o modelo...\n",
        "y_pred=svc.predict(x_test) # Predizendo...\n",
        "acc_svc=round(metrics.accuracy_score(y_pred,y_test)*100,1) # Nesta etapa, vamos avaliar a acurácia. Ou seja, Previsões x Resultados.\n",
        "print(acc_svc,\"% de acurácia\") # Exibindo o resultado..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93.6 % de acurácia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz6Ixg-yYbsW"
      },
      "source": [
        "**III - Floresta Aleatória:**\n",
        "\n",
        "Trata-se de um método de aprendizagem de conjunto para classificação, regressão e outras tarefas que operam construindo uma infinidade de árvores de decisão no momento do treinamento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcKKko7YXf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199a06e7-f46f-4261-d0cd-1a6fee63cf88"
      },
      "source": [
        "# Vamos importar o nosso modelo:\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest=RandomForestClassifier(n_estimators=100) # Criando o modelo...\n",
        "forest.fit(x_train,y_train) # Treinando o modelo...\n",
        "y_pred=forest.predict(x_test) # Predizendo...\n",
        "acc_forest=round(metrics.accuracy_score(y_pred,y_test)*100,1) # Nesta etapa, vamos avaliar a acurácia. Ou seja, Previsões x Resultados.\n",
        "print(acc_forest,\"% de acurácia\") # Exibindo o resultado..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.5 % de acurácia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfL5db7VaZn5"
      },
      "source": [
        "**08. Avaliando a eficácia:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqjWGvkXakzv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "77a677fc-9db2-44aa-c5bc-ee86e0fb1e2b"
      },
      "source": [
        "modelos=pd.DataFrame({'Modelos':['Regressão Logística','Máquina de Vetores de Suporte',\\\n",
        "                    'Floresta Aleatória'],\\\n",
        "         'Score':[acc_logreg,acc_svc,acc_forest]})\n",
        "\n",
        "modelos.sort_values(by=\"Score\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelos</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regressão Logística</td>\n",
              "      <td>97.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Floresta Aleatória</td>\n",
              "      <td>96.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Máquina de Vetores de Suporte</td>\n",
              "      <td>93.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Modelos  Score\n",
              "0            Regressão Logística   97.1\n",
              "2             Floresta Aleatória   96.5\n",
              "1  Máquina de Vetores de Suporte   93.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3JWzXVegd4x"
      },
      "source": [
        "**09. Conclusão:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "063VRyBmdEfi"
      },
      "source": [
        "**Vamos voltar um pouco, vimos o % de acurácia de cada modelo, mas o que é isso?**\n",
        "\n",
        "A acurácia é a proximidade de um resultado com o seu valor de referência real. Dessa forma, quanto maior a acurácia, mais próximo da referência ou valor real é o resultado encontrado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaUJZAmYdb6i"
      },
      "source": [
        "**10. Referências:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxqM6XiHh7dK"
      },
      "source": [
        "Data School: [Comparing Machine Learning Models in Scikit-Learn](https://www.youtube.com/watch?v=0pP4EwWJgIU)\n",
        "\n",
        "Janio Martinez Bachmann: Credit Fraud - Dealing with imbalanced dataset > [Kaggle Notebook](https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets)\n",
        "\n",
        "Pedro Marcelino: Comprehensive data exploration with Python > [Kaggle Notebook](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python)\n",
        "\n",
        "Manav Sehgal: Titanic Data Science Solution > [Kaggle Notebook](https://www.kaggle.com/startupsci/titanic-data-science-solutions)"
      ]
    }
  ]
}